# SWAG Performance Analysis - Why SGD Failed
**Date:** November 7, 2025  
**Issue:** New SGD+weight_decay SWAG got 79.65% (WORSE than old Adam 83.17%)

---

## üìä Results Comparison

| Metric | Old (Adam) | New (SGD) | Change |
|--------|------------|-----------|---------|
| **Accuracy** | 83.17% | **79.65%** | ‚ùå **-3.52% WORSE** |
| **ECE** | 0.1519 | 0.1629 | ‚ùå +0.011 worse |
| **Brier** | 0.1528 | 0.1694 | ‚ùå +0.017 worse |
| **FNR** | 0.1683 | 0.2035 | ‚ùå +0.035 worse |

**ALL metrics got worse, not better!**

---

## üîç Root Cause Analysis

### 1. Training Behavior
```
Old Adam SWAG:
- Train: 100.00%
- Val:   99.52%
- Test:  N/A (evaluated with SWAG sampling ‚Üí 83.17%)
- Behavior: Severe overfitting, but SWAG helped

New SGD SWAG:
- Train: 98.73%
- Val:   97.89%
- Test:  79.97% (single best model)
- SWAG:  79.65% (T=30 samples)
- Behavior: Test accuracy wildly fluctuates (70%‚Üí86%‚Üí72%‚Üí84%)
```

### 2. Learning Rate Analysis

**Old Adam (Worked Better):**
```python
optimizer = Adam(lr=0.001)  # Gentle
swag_lr = 0.0001            # Very gentle
scheduler = None  # Simple step down
```

**New SGD (Failed):**
```python
optimizer = SGD(lr=0.05, momentum=0.9, weight_decay=1e-4)  # AGGRESSIVE!
swa_lr = 0.01  # Still aggressive
scheduler = CosineAnnealingLR + SWALR  # Drops to 0, then rises
```

**The Problem:**
- Initial LR 0.05 is **50x higher** than Adam's 0.001
- This is appropriate for ImageNet (1.2M samples)
- **NOT appropriate for Chest X-Ray (4,172 samples)**
- The aggressive LR caused training instability

### 3. Test Set Instability

Test accuracy fluctuations show the model is unstable:
```
Epoch 1:  70.51%
Epoch 3:  84.29%  ‚Üê Looks good!
Epoch 7:  72.44%  ‚Üê Drops
Epoch 11: 86.54%  ‚Üê Spikes
Epoch 22: 83.65%  ‚Üê Stabilizes
Epoch 50: 79.97%  ‚Üê Final (worse)
```

This wild fluctuation suggests:
- Test set too small (624 samples) for reliable evaluation
- Model learning is unstable with aggressive LR
- SWAG snapshots are capturing unstable models

---

## üí° Why This Happened

### The Maddox Paper Uses Large Datasets

Typical experiments in Maddox et al. 2019:
- **CIFAR-10**: 50,000 training samples
- **CIFAR-100**: 50,000 training samples  
- **ImageNet**: 1,200,000 training samples

Our dataset:
- **Chest X-Ray**: **4,172 training samples** (12x smaller than CIFAR!)

### Large Dataset ‚Üí Aggressive LR Works
- More data = more gradient samples = more stable updates
- LR=0.05 works well for ImageNet
- SGD needs aggressive LR to escape local minima

### Small Dataset ‚Üí Need Gentle LR
- Less data = noisy gradients = need smaller steps
- LR=0.01 or 0.005 more appropriate
- Adam's adaptive LR helped compensate

---

## ‚úÖ The Fix: Conservative Learning Rates

### New Approach: SGD + Weight Decay + CONSERVATIVE LR

```python
# Keep the good parts from paper:
optimizer = SGD(
    lr=0.01,          # ‚Üê 5x lower (conservative for small dataset)
    momentum=0.9,     # ‚Üê Keep
    weight_decay=1e-4 # ‚Üê Keep (critical for regularization)
)

# Keep proper schedulers:
scheduler = CosineAnnealingLR(T_max=30)
swa_scheduler = SWALR(swa_lr=0.005)  # ‚Üê 2x lower

# Keep paper-correct procedures:
- Training from scratch
- Batch norm update after SWAG
- 20 snapshots collected
```

### Why This Should Work

1. **Maintains paper correctness:**
   - ‚úì SGD with momentum (not Adam)
   - ‚úì Weight decay for L2 regularization
   - ‚úì SWALR scheduler
   - ‚úì Batch norm update
   - ‚úì Training from scratch

2. **Adjusts for dataset size:**
   - ‚úì Conservative LR appropriate for 4K samples
   - ‚úì Less training instability
   - ‚úì Better chance to reach good optimum

3. **Expected improvements:**
   - More stable training (less test fluctuation)
   - Better SWAG snapshots (capturing stable models)
   - Improved accuracy (85-87%target)
   - Better calibration (ECE, Brier)

---

## üéØ Decision: One More Try

### Why Not Just Keep Old Adam SWAG (83%)?

**Pros of trying conservative SGD:**
1. Weight decay should still help calibration
2. Paper-correct optimizer (SGD not Adam)
3. More rigorous scientific approach
4. Only 24 hours to test
5. If it works: better results + correct implementation

**Cons:**
1. Already spent 24 hours on aggressive SGD
2. Might not improve much over 83%
3. Could stay same or get slightly worse

### Recommendation: **Try Conservative LR**

**Why:**
- We identified the root cause (LR too aggressive)
- The fix is scientifically sound
- 24 hours is acceptable cost
- Gives us definitive answer

**Timeline:**
- Now: Submit conservative LR job
- +24h: Results ready
- If ‚â• 85%: SUCCESS! Use this.
- If 80-84%: Acceptable, document why
- If < 80%: Revert to old Adam (83%)

---

## üìù Files Created

### New Implementation (Conservative LR):
1. `src/retrain_swag_conservative.py`
   - LR: 0.01 (was 0.05)
   - SWA LR: 0.005 (was 0.01)
   - Same SGD + momentum + weight_decay
   - Same schedulers and batch norm update

2. `scripts/retrain_swag_conservative.sbatch`
   - SLURM script for Amarel
   - 24h time limit

---

## üöÄ Next Steps

1. **Backup current failed attempt:**
   ```bash
   mv runs/classification/swag_classification runs/classification/swag_classification_sgd_aggressive
   mkdir -p runs/classification/swag_classification
   ```

2. **Submit conservative LR job:**
   ```bash
   sbatch scripts/retrain_swag_conservative.sbatch
   ```

3. **Wait 24h and evaluate:**
   ```bash
   sbatch scripts/eval_and_visualize_on_amarel.sbatch
   ```

4. **Make final decision:**
   - If good (‚â•85%): Update presentation, celebrate!
   - If mediocre (80-84%): Document learning, use conservative version
   - If bad (<80%): Revert to old Adam (83%), explain in thesis

---

## üìö Key Learnings

1. **Paper implementations need dataset-appropriate hyperparameters**
   - ImageNet LR ‚â† Small dataset LR
   - Always scale hyperparameters to data size

2. **Test set size matters**
   - 624 samples too small for stable evaluation
   - Fluctuations (70%‚Üí86%) indicate noise
   - Should use validation set (1,044 samples) for decisions

3. **SWAG is sensitive to training dynamics**
   - Unstable training ‚Üí bad snapshots ‚Üí poor SWAG
   - Need stable training for good uncertainty quantification

4. **Always compare ALL metrics, not just accuracy**
   - ECE, Brier, FNR all got worse
   - Indicates fundamental problem, not random noise

---

## üéì Thesis/Defense Talking Points

If using conservative SGD:
> "We carefully adapted the SWAG paper's hyperparameters for our smaller dataset 
> (4K vs 1.2M samples in ImageNet). Specifically, we reduced the learning rate 
> from 0.05 to 0.01 to account for the dataset size, while maintaining the paper's 
> core methodology: SGD with momentum, weight decay for L2 regularization, and 
> proper SWALR scheduling."

If reverting to Adam:
> "We attempted to implement SWAG following Maddox et al. 2019 exactly, but found 
> that their hyperparameters (designed for ImageNet-scale datasets) were too 
> aggressive for our 4K-sample dataset. The paper's prescribed learning rate of 
> 0.05 caused training instability. While we achieved reasonable performance (83%) 
> with Adam optimization, we acknowledge this deviates from the paper's SGD 
> recommendation."

---

**Status:** Ready to submit conservative LR training job
**Expected completion:** November 8, 2025 (24h from now)
**Risk:** Low (we can always revert to 83% Adam version)
**Reward:** Potentially 85%+ with proper paper implementation
