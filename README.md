# Medical Image Analysis with Uncertainty Quantification

This repository implements and evaluates **uncertainty quantification (UQ) methods** for medical imaging tasks, including both **segmentation** and **classification**, with a focus on the new **Conformal Risk Control** method.

## ğŸ†• New: Medical Image Classification + Conformal Risk Control

We've extended the project to include **medical image classification** with **Conformal Risk Control**, a state-of-the-art uncertainty quantification method that provides provable risk guarantees.

**Quick Start:** See [`docs/CLASSIFICATION_QUICK_START.md`](docs/CLASSIFICATION_QUICK_START.md)

## ğŸ¯ Project Overview

This project explores uncertainty quantification in medical imaging through two complementary tasks:

### 1. Segmentation (Completed âœ…)
**Goal**: Pixel-wise brain tumor segmentation with uncertainty estimates
**Dataset**: BraTS2020
**Methods**: Baseline, MC Dropout, Deep Ensemble, SWAG

### 2. Classification (New ğŸ†•)
**Goal**: Image-level medical diagnosis with risk-controlled predictions
**Datasets**: Chest X-Ray Pneumonia, OCT Retinal, Brain Tumor MRI
**Methods**: Baseline, MC Dropout, Deep Ensemble, **Conformal Risk Control**

## ğŸ”¬ Uncertainty Quantification Methods

### Segmentation Methods
### Segmentation Methods

1. **Baseline** - Standard U-Net (no uncertainty)
2. **MC Dropout** - Monte Carlo Dropout sampling
3. **Deep Ensemble** - Multiple independent models
4. **SWAG** - Stochastic Weight Averaging-Gaussian

### Classification Methods 

1. **Baseline** - Standard ResNet-18 classifier
2. **MC Dropout** - Monte Carlo Dropout for uncertainty
3. **Deep Ensemble** - Multiple independent ResNet models
4. **Conformal Risk Control** â­ - Distribution-free risk control with provable guarantees

#### What is Conformal Risk Control?

Unlike standard conformal prediction (which only guarantees coverage), **Conformal Risk Control** allows you to control *any* risk metric:

- **False Negative Rate:** "Miss disease â‰¤ 5% of time"
- **Precision:** "False alarms â‰¤ 10%"
- **Set Size:** "Prediction set â‰¤ 2 labels on average"
- **Custom Metrics:** Define your own risk functional

**Key Advantage:** Provable guarantees with finite-sample correction, making it ideal for safety-critical medical applications.

**Paper:** Angelopoulos et al. "Conformal Risk Control" (2022) - See `papers/Conformal Risk Control.pdf`

## ğŸ“Š Key Results

### Segmentation Results (BraTS2020)

| Method | Dice Score | ECE | Uncertainty | Rank |
|--------|-----------|-----|-------------|------|
| **Deep Ensemble** | 0.7550 | 0.9589 | 0.0158 | ğŸ¥‡ 1st |
| **SWAG** | 0.7419 | 0.9656 | 0.0026 | ğŸ¥ˆ 2nd |
| **MC Dropout** | 0.7403 | 0.9663 | 0.0011 | ğŸ¥‰ 3rd |
| **Baseline** | 0.7401 | 0.9673 | N/A | 4th |

- **Evaluation**: 80 test samples from BraTS2020 dataset
- **Platform**: Rutgers Amarel HPC with NVIDIA GPUs
- **Key Finding**: Deep Ensemble achieved best performance

### Classification Results (Expected)

Results will be available after running experiments. Expected accuracy on Chest X-Ray Pneumonia:

| Method | Expected Accuracy | Notes |
|--------|------------------|-------|
| **Baseline** | ~90-95% | Standard ResNet-18 |
| **MC Dropout** | ~90-95% | Similar accuracy + uncertainty |
| **Deep Ensemble** | ~92-96% | Typically 1-3% improvement |
| **CRC (FNR Î±=0.05)** | N/A | Guarantees FNR â‰¤ 5% |
| **CRC (Size Î±=2.0)** | N/A | Avg prediction set â‰¤ 2 |

## ğŸ“ Repository Structure

```
uq_capstone/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ src/                     # Source code
â”‚   # Segmentation (original)
â”‚   â”œâ”€â”€ data_utils.py       # Data loading and preprocessing
â”‚   â”œâ”€â”€ model_utils.py      # U-Net architecture
â”‚   â”œâ”€â”€ uq_methods.py       # UQ method implementations
â”‚   â”œâ”€â”€ swag.py             # SWAG implementation (FIXED)
â”‚   â”œâ”€â”€ train_baseline.py   # Train baseline model
â”‚   â”œâ”€â”€ train_mc_dropout.py # Train MC Dropout
â”‚   â”œâ”€â”€ train_ensemble_member.py # Train ensemble member
â”‚   â”œâ”€â”€ train_swag.py       # Train SWAG model
â”‚   â”œâ”€â”€ evaluate_uq.py      # Original evaluation script
â”‚   â””â”€â”€ evaluate_uq_FIXED_v2.py # Fixed evaluation
â”‚   
â”‚   # Classification (NEW ğŸ†•)
â”‚   â”œâ”€â”€ data_utils_classification.py     # Medical image datasets
â”‚   â”œâ”€â”€ conformal_risk_control.py        # CRC implementation
â”‚   â”œâ”€â”€ train_classifier_baseline.py     # Train classifier
â”‚   â”œâ”€â”€ train_classifier_mc_dropout.py   # Train with dropout
â”‚   â”œâ”€â”€ train_classifier_ensemble_member.py # Train ensemble
â”‚   â””â”€â”€ evaluate_uq_classification.py    # Comprehensive evaluation
â”‚
â”œâ”€â”€ scripts/                 # SLURM batch scripts for Amarel HPC
â”‚   # Segmentation
â”‚   â”œâ”€â”€ train_baseline.sbatch
â”‚   â”œâ”€â”€ train_mc_dropout.sbatch
â”‚   â”œâ”€â”€ train_ensemble.sbatch
â”‚   â”œâ”€â”€ train_swag.sbatch
â”‚   â”œâ”€â”€ evaluate_uq.sbatch
â”‚   â””â”€â”€ run_all_experiments.sh
â”‚   
â”‚   # Classification (NEW ğŸ†•)
â”‚   â”œâ”€â”€ train_classifier_baseline.sbatch
â”‚   â”œâ”€â”€ train_classifier_mc_dropout.sbatch
â”‚   â”œâ”€â”€ train_classifier_ensemble.sbatch
â”‚   â”œâ”€â”€ evaluate_classification.sbatch
â”‚   â””â”€â”€ run_all_classification_experiments.sh
â”‚
â”œâ”€â”€ analysis/                # UQ analysis scripts
â”‚   â”œâ”€â”€ analyze_uq_metrics.py    # Compute calibration metrics
â”‚   â”œâ”€â”€ visualize_uq.py          # Generate visualizations
â”‚   â””â”€â”€ generate_uq_report.py    # Create comprehensive report
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ START_HERE.md       # Original quick start guide
â”‚   â”œâ”€â”€ CLASSIFICATION_QUICK_START.md  # ğŸ†• Classification quick start
â”‚   â”œâ”€â”€ CLASSIFICATION_SETUP_GUIDE.md  # ğŸ†• Detailed setup guide
â”‚   â””â”€â”€ ... (other documentation)
â”‚
â”œâ”€â”€ papers/                  # Reference papers
â”‚   â”œâ”€â”€ baseline_for_uncertainty_DL.pdf
â”‚   â””â”€â”€ Conformal Risk Control.pdf  # ğŸ†• CRC paper
â”‚
â”œâ”€â”€ data/                    # Datasets (gitignored)
â”‚   â”œâ”€â”€ brats/              # BraTS segmentation data
â”‚   â”œâ”€â”€ chest_xray/         # ğŸ†• Chest X-Ray classification
â”‚   â”œâ”€â”€ oct_retinal/        # ğŸ†• OCT Retinal images
â”‚   â””â”€â”€ brain_tumor/        # ğŸ†• Brain Tumor MRI
â”‚
â””â”€â”€ runs/                    # Training/evaluation outputs (gitignored)
    â”œâ”€â”€ baseline/           # Segmentation runs
    â”œâ”€â”€ mc_dropout/
    â”œâ”€â”€ ensemble/
    â”œâ”€â”€ swag/
    â”œâ”€â”€ evaluation/
    â””â”€â”€ classification/     # ğŸ†• Classification runs
        â”œâ”€â”€ baseline/
        â”œâ”€â”€ mc_dropout/
        â”œâ”€â”€ ensemble/
        â””â”€â”€ evaluation/
```

## ğŸš€ Quick Start

### For Segmentation (Original)

See **[START_HERE.md](docs/START_HERE.md)** for the complete segmentation setup.

### For Classification (NEW ğŸ†•)

**Fast Track:** Follow **[CLASSIFICATION_QUICK_START.md](docs/CLASSIFICATION_QUICK_START.md)**

```bash
# 1. Upload code to Amarel (see quick start guide)

# 2. Download dataset (Chest X-Ray Pneumonia recommended)
cd /scratch/$USER/uq_capstone/data
kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
unzip chest-xray-pneumonia.zip -d chest_xray/

# 3. Run all experiments
cd /scratch/$USER/uq_capstone
bash scripts/run_all_classification_experiments.sh

# 4. Monitor jobs
squeue -u $USER
tail -f runs/classification/*/train_*.out

# 5. Get results (after ~30-40 hours)
cat runs/classification/evaluation/all_results.json
```

### Datasets Available

| Dataset | Classes | Size | Medical Task | Recommended |
|---------|---------|------|--------------|-------------|
| **Chest X-Ray** | 2 | ~5,863 | Pneumonia detection | â­ Yes (start here) |
| **OCT Retinal** | 4 | ~84,495 | Retinopathy screening | Multi-class |
| **Brain Tumor** | 4 | ~7,023 | Tumor classification | Continuity with BraTS |

## ğŸ”§ Key Technical Details

### SWAG Fix (Critical)

**Problem**: Original SWAG implementation had unbounded variance causing:
- Variance values up to 226M
- Weight explosion (sampled weights up to 249K)
- Catastrophic predictions (Dice = 0.14, Uncertainty = NaN)

**Solution**: Added `max_var` parameter to cap variance:
```python
# In swag.py
swag_model = SWAG(base_model, max_num_models=20, max_var=1.0)
var = torch.clamp(self.sq_mean - self.mean ** 2, self.var_clamp, self.max_var)
```

**Result**: SWAG now works correctly with Dice=0.74, competitive with other methods.

### Dataset

- **Source**: BraTS2020 (Brain Tumor Segmentation Challenge)
- **Training samples**: 320 slices
- **Validation samples**: 40 slices
- **Test samples**: 80 slices
- **Task**: Binary segmentation (tumor vs background)
- **Format**: `.npz` files with preprocessed 2D slices

### Training Configuration

- **Architecture**: U-Net with 4 encoder/decoder blocks
- **Loss**: Dice Loss
- **Optimizer**: Adam (lr=1e-3)
- **Epochs**: 30 for baseline, 20 for SWAG
- **Batch size**: 16
- **Hardware**: NVIDIA A100 GPUs on Amarel HPC

## ğŸ“ˆ Evaluation Metrics

1. **Segmentation Quality**:
   - Dice Score
   - IoU (Intersection over Union)

2. **Calibration Metrics**:
   - ECE (Expected Calibration Error)
   - MCE (Maximum Calibration Error)
   - Brier Score

3. **Uncertainty Quality**:
   - Uncertainty-Error Correlation (Pearson, Spearman)
   - AUROC for error detection
   - Reliability diagrams

## ğŸ“š Documentation

### Quick Start Guides
- **[CLASSIFICATION_QUICK_START.md](docs/CLASSIFICATION_QUICK_START.md)** ğŸ†• - Fast track for classification experiments
- **[START_HERE.md](docs/START_HERE.md)** - Original segmentation setup guide

### Detailed Guides
- **[CLASSIFICATION_SETUP_GUIDE.md](docs/CLASSIFICATION_SETUP_GUIDE.md)** ğŸ†• - Comprehensive classification documentation
- **[QUICK_START_UQ.md](docs/QUICK_START_UQ.md)** - UQ segmentation experiments
- **[SWAG_FIXED_SUCCESS.md](docs/SWAG_FIXED_SUCCESS.md)** - SWAG debugging journey
- **[UQ_EXPERIMENTS_GUIDE.md](docs/UQ_EXPERIMENTS_GUIDE.md)** - Detailed experiment guide

### Papers
- **[Conformal Risk Control.pdf](papers/Conformal%20Risk%20Control.pdf)** ğŸ†• - Angelopoulos et al. (2022)
- **baseline_for_uncertainty_DL.pdf** - General UQ reference

## ğŸ“ References

### Papers

**Conformal Risk Control (NEW):**
- Angelopoulos et al. "Conformal Risk Control" (2022)
- [Paper](https://arxiv.org/abs/2208.02814) | Local: `papers/Conformal Risk Control.pdf`

**Uncertainty Quantification Methods:**
- **SWAG**: Maddox et al. "A Simple Baseline for Bayesian Uncertainty in Deep Learning" (NeurIPS 2019)
- **MC Dropout**: Gal & Ghahramani "Dropout as a Bayesian Approximation" (ICML 2016)
- **Deep Ensembles**: Lakshminarayanan et al. "Simple and Scalable Predictive Uncertainty" (NIPS 2017)

**Datasets:**
- **BraTS**: Menze et al. "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)" (IEEE TMI 2015)
- **Chest X-Ray Pneumonia**: Kermany et al. "Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification" (Cell 2018)

### Medical Datasets

- **Chest X-Ray Pneumonia**: [Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
- **OCT Retinal Images**: [Kaggle](https://www.kaggle.com/datasets/paultimothymooney/kermany2018)
- **Brain Tumor MRI**: [Kaggle](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)

## ğŸ¤ Contributing

This is a research project for uncertainty quantification in medical image segmentation. For questions or issues, please open a GitHub issue.

## ğŸ“„ License

This project is for academic research purposes.

## ğŸ‘¥ Authors

- Phan Nguyen Huong Le; Advisor: Gemma Moran
